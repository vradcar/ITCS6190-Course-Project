{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668e1db9",
   "metadata": {},
   "source": [
    "# Complex Queries with PySpark\n",
    "## LinkedIn Job Postings Analysis using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873846ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\varad\\anaconda3\\envs\\cloud\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install PySpark if not already installed\n",
    "!pip install pyspark matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "966ab68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, desc, avg, rank, window\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f87072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 4.0.1\n",
      "Spark Session Created: <pyspark.sql.session.SparkSession object at 0x000001EA2824BA50>\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LinkedIn Job Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark Session Created: {spark}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51722c68",
   "metadata": {},
   "source": [
    "## Load Data into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ee8740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Postings count: 1160234\n",
      "Job skills count: 213768\n",
      "Postings count: 1160234\n",
      "Job skills count: 213768\n",
      "Industries count: 422\n",
      "Industries count: 422\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "postings = spark.read.csv(r\"../data/postings_cleaned.csv\", header=True, inferSchema=True)\n",
    "job_skills = spark.read.csv(r\"../data/jobs/job_skills.csv\", header=True, inferSchema=True)\n",
    "skill_map = spark.read.csv(r\"../data/mappings/skills.csv\", header=True, inferSchema=True)\n",
    "job_industries = spark.read.csv(r\"../data/jobs/job_industries.csv\", header=True, inferSchema=True)\n",
    "industry_map = spark.read.csv(r\"../data/mappings/industries.csv\", header=True, inferSchema=True)\n",
    "company_ind = spark.read.csv(r\"../data/companies/company_industries.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Postings count: {postings.count()}\")\n",
    "print(f\"Job skills count: {job_skills.count()}\")\n",
    "print(f\"Industries count: {industry_map.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6f6e8",
   "metadata": {},
   "source": [
    "## Complex Query 1: Top Skills by Industry with Ranking\n",
    "This query demonstrates:\n",
    "- Multiple JOIN operations\n",
    "- Window functions for ranking\n",
    "- GROUP BY and aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c671d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 10 Skills by Industry ===\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "|industry_name                                   |skill_name            |skill_count|rank|\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "|Abrasives and Nonmetallic Minerals Manufacturing|Engineering           |1          |1   |\n",
      "|Accessible Architecture and Design              |Design                |5          |1   |\n",
      "|Accessible Architecture and Design              |Project Management    |4          |2   |\n",
      "|Accessible Architecture and Design              |Engineering           |4          |2   |\n",
      "|Accessible Architecture and Design              |Information Technology|3          |4   |\n",
      "|Accessible Architecture and Design              |Strategy/Planning     |2          |5   |\n",
      "|Accessible Architecture and Design              |Accounting/Auditing   |1          |6   |\n",
      "|Accessible Architecture and Design              |Sales                 |1          |6   |\n",
      "|Accommodation and Food Services                 |Customer Service      |2          |1   |\n",
      "|Accommodation and Food Services                 |Administrative        |1          |2   |\n",
      "|Accommodation and Food Services                 |Training              |1          |2   |\n",
      "|Accommodation and Food Services                 |Human Resources       |1          |2   |\n",
      "|Accommodation and Food Services                 |Strategy/Planning     |1          |2   |\n",
      "|Accommodation and Food Services                 |Other                 |1          |2   |\n",
      "|Accommodation and Food Services                 |Management            |1          |2   |\n",
      "|Accommodation and Food Services                 |Analyst               |1          |2   |\n",
      "|Accommodation and Food Services                 |Sales                 |1          |2   |\n",
      "|Accommodation and Food Services                 |Distribution          |1          |2   |\n",
      "|Accommodation and Food Services                 |Business Development  |1          |2   |\n",
      "|Accounting                                      |Accounting/Auditing   |1285       |1   |\n",
      "|Accounting                                      |Finance               |907        |2   |\n",
      "|Accounting                                      |Information Technology|196        |3   |\n",
      "|Accounting                                      |Administrative        |153        |4   |\n",
      "|Accounting                                      |Sales                 |142        |5   |\n",
      "|Accounting                                      |Consulting            |129        |6   |\n",
      "|Accounting                                      |Management            |119        |7   |\n",
      "|Accounting                                      |Business Development  |100        |8   |\n",
      "|Accounting                                      |General Business      |84         |9   |\n",
      "|Accounting                                      |Strategy/Planning     |83         |10  |\n",
      "|Administration of Justice                       |Legal                 |15         |1   |\n",
      "|Administration of Justice                       |Administrative        |13         |2   |\n",
      "|Administration of Justice                       |Strategy/Planning     |9          |3   |\n",
      "|Administration of Justice                       |Customer Service      |3          |4   |\n",
      "|Administration of Justice                       |Other                 |2          |5   |\n",
      "|Administration of Justice                       |Management            |2          |5   |\n",
      "|Administration of Justice                       |Information Technology|2          |5   |\n",
      "|Administration of Justice                       |Business Development  |2          |5   |\n",
      "|Administration of Justice                       |Sales                 |1          |9   |\n",
      "|Administration of Justice                       |General Business      |1          |9   |\n",
      "|Administrative and Support Services             |Customer Service      |62         |1   |\n",
      "|Administrative and Support Services             |Administrative        |49         |2   |\n",
      "|Administrative and Support Services             |Legal                 |12         |3   |\n",
      "|Administrative and Support Services             |General Business      |8          |4   |\n",
      "|Administrative and Support Services             |Finance               |6          |5   |\n",
      "|Administrative and Support Services             |Project Management    |3          |6   |\n",
      "|Administrative and Support Services             |Management            |3          |6   |\n",
      "|Administrative and Support Services             |Information Technology|3          |6   |\n",
      "|Administrative and Support Services             |Accounting/Auditing   |3          |6   |\n",
      "|Administrative and Support Services             |Other                 |3          |6   |\n",
      "|Administrative and Support Services             |Human Resources       |3          |6   |\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "only showing top 50 rows\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "|industry_name                                   |skill_name            |skill_count|rank|\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "|Abrasives and Nonmetallic Minerals Manufacturing|Engineering           |1          |1   |\n",
      "|Accessible Architecture and Design              |Design                |5          |1   |\n",
      "|Accessible Architecture and Design              |Project Management    |4          |2   |\n",
      "|Accessible Architecture and Design              |Engineering           |4          |2   |\n",
      "|Accessible Architecture and Design              |Information Technology|3          |4   |\n",
      "|Accessible Architecture and Design              |Strategy/Planning     |2          |5   |\n",
      "|Accessible Architecture and Design              |Accounting/Auditing   |1          |6   |\n",
      "|Accessible Architecture and Design              |Sales                 |1          |6   |\n",
      "|Accommodation and Food Services                 |Customer Service      |2          |1   |\n",
      "|Accommodation and Food Services                 |Administrative        |1          |2   |\n",
      "|Accommodation and Food Services                 |Training              |1          |2   |\n",
      "|Accommodation and Food Services                 |Human Resources       |1          |2   |\n",
      "|Accommodation and Food Services                 |Strategy/Planning     |1          |2   |\n",
      "|Accommodation and Food Services                 |Other                 |1          |2   |\n",
      "|Accommodation and Food Services                 |Management            |1          |2   |\n",
      "|Accommodation and Food Services                 |Analyst               |1          |2   |\n",
      "|Accommodation and Food Services                 |Sales                 |1          |2   |\n",
      "|Accommodation and Food Services                 |Distribution          |1          |2   |\n",
      "|Accommodation and Food Services                 |Business Development  |1          |2   |\n",
      "|Accounting                                      |Accounting/Auditing   |1285       |1   |\n",
      "|Accounting                                      |Finance               |907        |2   |\n",
      "|Accounting                                      |Information Technology|196        |3   |\n",
      "|Accounting                                      |Administrative        |153        |4   |\n",
      "|Accounting                                      |Sales                 |142        |5   |\n",
      "|Accounting                                      |Consulting            |129        |6   |\n",
      "|Accounting                                      |Management            |119        |7   |\n",
      "|Accounting                                      |Business Development  |100        |8   |\n",
      "|Accounting                                      |General Business      |84         |9   |\n",
      "|Accounting                                      |Strategy/Planning     |83         |10  |\n",
      "|Administration of Justice                       |Legal                 |15         |1   |\n",
      "|Administration of Justice                       |Administrative        |13         |2   |\n",
      "|Administration of Justice                       |Strategy/Planning     |9          |3   |\n",
      "|Administration of Justice                       |Customer Service      |3          |4   |\n",
      "|Administration of Justice                       |Other                 |2          |5   |\n",
      "|Administration of Justice                       |Management            |2          |5   |\n",
      "|Administration of Justice                       |Information Technology|2          |5   |\n",
      "|Administration of Justice                       |Business Development  |2          |5   |\n",
      "|Administration of Justice                       |Sales                 |1          |9   |\n",
      "|Administration of Justice                       |General Business      |1          |9   |\n",
      "|Administrative and Support Services             |Customer Service      |62         |1   |\n",
      "|Administrative and Support Services             |Administrative        |49         |2   |\n",
      "|Administrative and Support Services             |Legal                 |12         |3   |\n",
      "|Administrative and Support Services             |General Business      |8          |4   |\n",
      "|Administrative and Support Services             |Finance               |6          |5   |\n",
      "|Administrative and Support Services             |Project Management    |3          |6   |\n",
      "|Administrative and Support Services             |Management            |3          |6   |\n",
      "|Administrative and Support Services             |Information Technology|3          |6   |\n",
      "|Administrative and Support Services             |Accounting/Auditing   |3          |6   |\n",
      "|Administrative and Support Services             |Other                 |3          |6   |\n",
      "|Administrative and Support Services             |Human Resources       |3          |6   |\n",
      "+------------------------------------------------+----------------------+-----------+----+\n",
      "only showing top 50 rows\n"
     ]
    }
   ],
   "source": [
    "# Clean industry map (drop nulls)\n",
    "industry_map_clean = industry_map.dropna()\n",
    "\n",
    "# Complex query: Top 10 skills per industry\n",
    "skills_by_industry = job_skills \\\n",
    "    .join(skill_map, \"skill_abr\") \\\n",
    "    .join(job_industries, \"job_id\") \\\n",
    "    .join(industry_map_clean, \"industry_id\") \\\n",
    "    .groupBy(\"industry_name\", \"skill_name\") \\\n",
    "    .agg(count(\"*\").alias(\"skill_count\")) \\\n",
    "    .withColumn(\"rank\", rank().over(Window.partitionBy(\"industry_name\").orderBy(desc(\"skill_count\")))) \\\n",
    "    .filter(col(\"rank\") <= 10) \\\n",
    "    .orderBy(\"industry_name\", \"rank\")\n",
    "\n",
    "print(\"=== Top 10 Skills by Industry ===\")\n",
    "skills_by_industry.show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54b433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 3771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_name</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>skill_count</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abrasives and Nonmetallic Minerals Manufacturing</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Design</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Project Management</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Strategy/Planning</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Accessible Architecture and Design</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Administrative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Strategy/Planning</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Management</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Distribution</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Accommodation and Food Services</td>\n",
       "      <td>Business Development</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>1285</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       industry_name              skill_name  \\\n",
       "0   Abrasives and Nonmetallic Minerals Manufacturing             Engineering   \n",
       "1                 Accessible Architecture and Design                  Design   \n",
       "2                 Accessible Architecture and Design      Project Management   \n",
       "3                 Accessible Architecture and Design             Engineering   \n",
       "4                 Accessible Architecture and Design  Information Technology   \n",
       "5                 Accessible Architecture and Design       Strategy/Planning   \n",
       "6                 Accessible Architecture and Design     Accounting/Auditing   \n",
       "7                 Accessible Architecture and Design                   Sales   \n",
       "8                    Accommodation and Food Services        Customer Service   \n",
       "9                    Accommodation and Food Services          Administrative   \n",
       "10                   Accommodation and Food Services                Training   \n",
       "11                   Accommodation and Food Services         Human Resources   \n",
       "12                   Accommodation and Food Services       Strategy/Planning   \n",
       "13                   Accommodation and Food Services                   Other   \n",
       "14                   Accommodation and Food Services              Management   \n",
       "15                   Accommodation and Food Services                 Analyst   \n",
       "16                   Accommodation and Food Services                   Sales   \n",
       "17                   Accommodation and Food Services            Distribution   \n",
       "18                   Accommodation and Food Services    Business Development   \n",
       "19                                        Accounting     Accounting/Auditing   \n",
       "\n",
       "    skill_count  rank  \n",
       "0             1     1  \n",
       "1             5     1  \n",
       "2             4     2  \n",
       "3             4     2  \n",
       "4             3     4  \n",
       "5             2     5  \n",
       "6             1     6  \n",
       "7             1     6  \n",
       "8             2     1  \n",
       "9             1     2  \n",
       "10            1     2  \n",
       "11            1     2  \n",
       "12            1     2  \n",
       "13            1     2  \n",
       "14            1     2  \n",
       "15            1     2  \n",
       "16            1     2  \n",
       "17            1     2  \n",
       "18            1     2  \n",
       "19         1285     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas for visualization\n",
    "skills_by_industry_pd = skills_by_industry.toPandas()\n",
    "print(f\"Total rows: {len(skills_by_industry_pd)}\")\n",
    "skills_by_industry_pd.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf698cbc",
   "metadata": {},
   "source": [
    "## Complex Query 2: Average Skills Required by Industry\n",
    "Analyzes skill complexity across different industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c95ae45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Average Skills Required by Industry ===\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "|industry_name                                      |avg_skills_required|total_jobs|\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "|Mattress and Blinds Manufacturing                  |3.0                |2         |\n",
      "|Household and Institutional Furniture Manufacturing|3.0                |1         |\n",
      "|Zoos and Botanical Gardens                         |3.0                |1         |\n",
      "|Wholesale Photography Equipment and Supplies       |3.0                |2         |\n",
      "|Metal Valve, Ball, and Roller Manufacturing        |3.0                |2         |\n",
      "|Artists and Writers                                |2.8636363636363638 |22        |\n",
      "|Retail Art Supplies                                |2.8                |20        |\n",
      "|Retail Recyclable Materials & Used Merchandise     |2.75               |4         |\n",
      "|Environmental Quality Programs                     |2.727272727272727  |11        |\n",
      "|Photography                                        |2.7037037037037037 |27        |\n",
      "|Paper & Forest Products                            |2.6666666666666665 |3         |\n",
      "|Performing Arts and Spectator Sports               |2.6666666666666665 |3         |\n",
      "|Magnetic and Optical Media Manufacturing           |2.6666666666666665 |3         |\n",
      "|Design                                             |2.6666666666666665 |9         |\n",
      "|Baked Goods Manufacturing                          |2.6666666666666665 |3         |\n",
      "|Medical and Diagnostic Laboratories                |2.6666666666666665 |3         |\n",
      "|Graphic Design                                     |2.6315789473684212 |19        |\n",
      "|Fine Art                                           |2.6                |5         |\n",
      "|Chemical Raw Materials Manufacturing               |2.56               |25        |\n",
      "|Newspaper Publishing                               |2.533333333333333  |15        |\n",
      "|Residential Building Construction                  |2.5                |8         |\n",
      "|Transportation Equipment Manufacturing             |2.5                |2         |\n",
      "|Wholesale Hardware, Plumbing, Heating Equipment    |2.5                |12        |\n",
      "|Online Media                                       |2.5                |2         |\n",
      "|Investment Advice                                  |2.5                |18        |\n",
      "|Book and Periodical Publishing                     |2.477386934673367  |199       |\n",
      "|Wireless Services                                  |2.4725274725274726 |273       |\n",
      "|Dairy Product Manufacturing                        |2.4651162790697674 |43        |\n",
      "|Community Development and Urban Planning           |2.411764705882353  |17        |\n",
      "|IT System Testing and Evaluation                   |2.4035087719298245 |57        |\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "only showing top 30 rows\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "|industry_name                                      |avg_skills_required|total_jobs|\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "|Mattress and Blinds Manufacturing                  |3.0                |2         |\n",
      "|Household and Institutional Furniture Manufacturing|3.0                |1         |\n",
      "|Zoos and Botanical Gardens                         |3.0                |1         |\n",
      "|Wholesale Photography Equipment and Supplies       |3.0                |2         |\n",
      "|Metal Valve, Ball, and Roller Manufacturing        |3.0                |2         |\n",
      "|Artists and Writers                                |2.8636363636363638 |22        |\n",
      "|Retail Art Supplies                                |2.8                |20        |\n",
      "|Retail Recyclable Materials & Used Merchandise     |2.75               |4         |\n",
      "|Environmental Quality Programs                     |2.727272727272727  |11        |\n",
      "|Photography                                        |2.7037037037037037 |27        |\n",
      "|Paper & Forest Products                            |2.6666666666666665 |3         |\n",
      "|Performing Arts and Spectator Sports               |2.6666666666666665 |3         |\n",
      "|Magnetic and Optical Media Manufacturing           |2.6666666666666665 |3         |\n",
      "|Design                                             |2.6666666666666665 |9         |\n",
      "|Baked Goods Manufacturing                          |2.6666666666666665 |3         |\n",
      "|Medical and Diagnostic Laboratories                |2.6666666666666665 |3         |\n",
      "|Graphic Design                                     |2.6315789473684212 |19        |\n",
      "|Fine Art                                           |2.6                |5         |\n",
      "|Chemical Raw Materials Manufacturing               |2.56               |25        |\n",
      "|Newspaper Publishing                               |2.533333333333333  |15        |\n",
      "|Residential Building Construction                  |2.5                |8         |\n",
      "|Transportation Equipment Manufacturing             |2.5                |2         |\n",
      "|Wholesale Hardware, Plumbing, Heating Equipment    |2.5                |12        |\n",
      "|Online Media                                       |2.5                |2         |\n",
      "|Investment Advice                                  |2.5                |18        |\n",
      "|Book and Periodical Publishing                     |2.477386934673367  |199       |\n",
      "|Wireless Services                                  |2.4725274725274726 |273       |\n",
      "|Dairy Product Manufacturing                        |2.4651162790697674 |43        |\n",
      "|Community Development and Urban Planning           |2.411764705882353  |17        |\n",
      "|IT System Testing and Evaluation                   |2.4035087719298245 |57        |\n",
      "+---------------------------------------------------+-------------------+----------+\n",
      "only showing top 30 rows\n"
     ]
    }
   ],
   "source": [
    "# Query: Average number of skills per job by industry\n",
    "multi_skill_jobs = job_skills \\\n",
    "    .groupBy(\"job_id\") \\\n",
    "    .agg(count(\"skill_abr\").alias(\"num_skills\")) \\\n",
    "    .join(job_industries, \"job_id\") \\\n",
    "    .join(industry_map_clean, \"industry_id\") \\\n",
    "    .groupBy(\"industry_name\") \\\n",
    "    .agg(\n",
    "        avg(\"num_skills\").alias(\"avg_skills_required\"),\n",
    "        count(\"job_id\").alias(\"total_jobs\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"avg_skills_required\"))\n",
    "\n",
    "print(\"=== Average Skills Required by Industry ===\")\n",
    "multi_skill_jobs.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f52597e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_name</th>\n",
       "      <th>avg_skills_required</th>\n",
       "      <th>total_jobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mattress and Blinds Manufacturing</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household and Institutional Furniture Manufact...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zoos and Botanical Gardens</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wholesale Photography Equipment and Supplies</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metal Valve, Ball, and Roller Manufacturing</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artists and Writers</td>\n",
       "      <td>2.863636</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Retail Art Supplies</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Retail Recyclable Materials &amp; Used Merchandise</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Environmental Quality Programs</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Photography</td>\n",
       "      <td>2.703704</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Design</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Magnetic and Optical Media Manufacturing</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Paper &amp; Forest Products</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baked Goods Manufacturing</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Medical and Diagnostic Laboratories</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Performing Arts and Spectator Sports</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fine Art</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chemical Raw Materials Manufacturing</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Newspaper Publishing</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        industry_name  avg_skills_required  \\\n",
       "0                   Mattress and Blinds Manufacturing             3.000000   \n",
       "1   Household and Institutional Furniture Manufact...             3.000000   \n",
       "2                          Zoos and Botanical Gardens             3.000000   \n",
       "3        Wholesale Photography Equipment and Supplies             3.000000   \n",
       "4         Metal Valve, Ball, and Roller Manufacturing             3.000000   \n",
       "5                                 Artists and Writers             2.863636   \n",
       "6                                 Retail Art Supplies             2.800000   \n",
       "7      Retail Recyclable Materials & Used Merchandise             2.750000   \n",
       "8                      Environmental Quality Programs             2.727273   \n",
       "9                                         Photography             2.703704   \n",
       "10                                             Design             2.666667   \n",
       "11           Magnetic and Optical Media Manufacturing             2.666667   \n",
       "12                            Paper & Forest Products             2.666667   \n",
       "13                          Baked Goods Manufacturing             2.666667   \n",
       "14                Medical and Diagnostic Laboratories             2.666667   \n",
       "15               Performing Arts and Spectator Sports             2.666667   \n",
       "16                                     Graphic Design             2.631579   \n",
       "17                                           Fine Art             2.600000   \n",
       "18               Chemical Raw Materials Manufacturing             2.560000   \n",
       "19                               Newspaper Publishing             2.533333   \n",
       "\n",
       "    total_jobs  \n",
       "0            2  \n",
       "1            1  \n",
       "2            1  \n",
       "3            2  \n",
       "4            2  \n",
       "5           22  \n",
       "6           20  \n",
       "7            4  \n",
       "8           11  \n",
       "9           27  \n",
       "10           9  \n",
       "11           3  \n",
       "12           3  \n",
       "13           3  \n",
       "14           3  \n",
       "15           3  \n",
       "16          19  \n",
       "17           5  \n",
       "18          25  \n",
       "19          15  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas\n",
    "avg_skills_pd = multi_skill_jobs.toPandas()\n",
    "avg_skills_pd.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb65266",
   "metadata": {},
   "source": [
    "## Complex Query 3: Cross-Industry Skill Overlap Analysis\n",
    "Identifies skills that are common across multiple industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46624cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Skills Across Multiple Industries ===\n",
      "+----------------------+--------------+\n",
      "|skill_name            |num_industries|\n",
      "+----------------------+--------------+\n",
      "|Management            |310           |\n",
      "|Sales                 |309           |\n",
      "|Business Development  |307           |\n",
      "|Information Technology|305           |\n",
      "|Engineering           |278           |\n",
      "|Manufacturing         |276           |\n",
      "|Other                 |273           |\n",
      "|Administrative        |261           |\n",
      "|Accounting/Auditing   |257           |\n",
      "|Finance               |254           |\n",
      "|Project Management    |251           |\n",
      "|Marketing             |234           |\n",
      "|Customer Service      |226           |\n",
      "|Analyst               |223           |\n",
      "|Design                |216           |\n",
      "|Human Resources       |215           |\n",
      "|Strategy/Planning     |213           |\n",
      "|Quality Assurance     |193           |\n",
      "|General Business      |190           |\n",
      "|Product Management    |178           |\n",
      "|Consulting            |178           |\n",
      "|Writing/Editing       |177           |\n",
      "|Art/Creative          |177           |\n",
      "|Research              |168           |\n",
      "|Supply Chain          |164           |\n",
      "|Public Relations      |159           |\n",
      "|Legal                 |152           |\n",
      "|Production            |150           |\n",
      "|Training              |147           |\n",
      "|Purchasing            |124           |\n",
      "+----------------------+--------------+\n",
      "only showing top 30 rows\n",
      "+----------------------+--------------+\n",
      "|skill_name            |num_industries|\n",
      "+----------------------+--------------+\n",
      "|Management            |310           |\n",
      "|Sales                 |309           |\n",
      "|Business Development  |307           |\n",
      "|Information Technology|305           |\n",
      "|Engineering           |278           |\n",
      "|Manufacturing         |276           |\n",
      "|Other                 |273           |\n",
      "|Administrative        |261           |\n",
      "|Accounting/Auditing   |257           |\n",
      "|Finance               |254           |\n",
      "|Project Management    |251           |\n",
      "|Marketing             |234           |\n",
      "|Customer Service      |226           |\n",
      "|Analyst               |223           |\n",
      "|Design                |216           |\n",
      "|Human Resources       |215           |\n",
      "|Strategy/Planning     |213           |\n",
      "|Quality Assurance     |193           |\n",
      "|General Business      |190           |\n",
      "|Product Management    |178           |\n",
      "|Consulting            |178           |\n",
      "|Writing/Editing       |177           |\n",
      "|Art/Creative          |177           |\n",
      "|Research              |168           |\n",
      "|Supply Chain          |164           |\n",
      "|Public Relations      |159           |\n",
      "|Legal                 |152           |\n",
      "|Production            |150           |\n",
      "|Training              |147           |\n",
      "|Purchasing            |124           |\n",
      "+----------------------+--------------+\n",
      "only showing top 30 rows\n"
     ]
    }
   ],
   "source": [
    "# Query: Skills appearing in multiple industries\n",
    "cross_industry_skills = job_skills \\\n",
    "    .join(skill_map, \"skill_abr\") \\\n",
    "    .join(job_industries, \"job_id\") \\\n",
    "    .join(industry_map_clean, \"industry_id\") \\\n",
    "    .select(\"skill_name\", \"industry_name\") \\\n",
    "    .distinct() \\\n",
    "    .groupBy(\"skill_name\") \\\n",
    "    .agg(count(\"industry_name\").alias(\"num_industries\")) \\\n",
    "    .orderBy(desc(\"num_industries\"))\n",
    "\n",
    "print(\"=== Skills Across Multiple Industries ===\")\n",
    "cross_industry_skills.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cf939e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_name</th>\n",
       "      <th>num_industries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Management</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Development</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Administrative</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Finance</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Project Management</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Marketing</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Analyst</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Design</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human Resources</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Strategy/Planning</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Quality Assurance</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>General Business</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Product Management</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                skill_name  num_industries\n",
       "0               Management             310\n",
       "1                    Sales             309\n",
       "2     Business Development             307\n",
       "3   Information Technology             305\n",
       "4              Engineering             278\n",
       "5            Manufacturing             276\n",
       "6                    Other             273\n",
       "7           Administrative             261\n",
       "8      Accounting/Auditing             257\n",
       "9                  Finance             254\n",
       "10      Project Management             251\n",
       "11               Marketing             234\n",
       "12        Customer Service             226\n",
       "13                 Analyst             223\n",
       "14                  Design             216\n",
       "15         Human Resources             215\n",
       "16       Strategy/Planning             213\n",
       "17       Quality Assurance             193\n",
       "18        General Business             190\n",
       "19      Product Management             178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_industry_pd = cross_industry_skills.toPandas()\n",
    "cross_industry_pd.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14618509",
   "metadata": {},
   "source": [
    "## Save Results for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de615a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o199.parquet.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)\r\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:369)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\t\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\t\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\t\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\t\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\t\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t\t... 1 more\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:601)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:622)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:645)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:742)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1954)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1912)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1885)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$install$1(ShutdownHookManager.scala:194)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n\tat scala.Option.fold(Option.scala:263)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:195)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:55)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:53)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:159)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala:63)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:250)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:99)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:379)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:521)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:492)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:569)\r\n\t... 27 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m../analytics_output/query_results\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Save as parquet for efficient storage\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mskills_by_industry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../analytics_output/query_results/skills_by_industry\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m multi_skill_jobs.write.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).parquet(\u001b[33m\"\u001b[39m\u001b[33m../analytics_output/query_results/avg_skills_by_industry\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m cross_industry_skills.write.mode(\u001b[33m\"\u001b[39m\u001b[33moverwrite\u001b[39m\u001b[33m\"\u001b[39m).parquet(\u001b[33m\"\u001b[39m\u001b[33m../analytics_output/query_results/cross_industry_skills\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\varad\\anaconda3\\envs\\cloud\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:2003\u001b[39m, in \u001b[36mDataFrameWriter.parquet\u001b[39m\u001b[34m(self, path, mode, partitionBy, compression)\u001b[39m\n\u001b[32m   2001\u001b[39m     \u001b[38;5;28mself\u001b[39m.partitionBy(partitionBy)\n\u001b[32m   2002\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(compression=compression)\n\u001b[32m-> \u001b[39m\u001b[32m2003\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\varad\\anaconda3\\envs\\cloud\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1361\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\varad\\anaconda3\\envs\\cloud\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpy4j\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    284\u001b[39m     converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\varad\\anaconda3\\envs\\cloud\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    325\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    328\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    329\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    332\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    333\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o199.parquet.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)\r\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)\r\n\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)\r\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:369)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller\r\n\t\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:789)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:298)\r\n\t\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:314)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:1116)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:798)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:838)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:837)\r\n\t\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:810)\r\n\t\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:988)\r\n\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\t\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:190)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:268)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)\r\n\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)\r\n\t\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)\r\n\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)\r\n\t\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)\r\n\t\tat org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)\r\n\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)\r\n\t\tat java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n\t\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n\t\t... 1 more\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:601)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:622)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:645)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:742)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1954)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1912)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1885)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$install$1(ShutdownHookManager.scala:194)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\r\n\tat scala.Option.fold(Option.scala:263)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:195)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:55)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:53)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:159)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala:63)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:250)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:99)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:379)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:961)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:521)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:492)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:569)\r\n\t... 27 more\r\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs(\"../analytics_output/query_results\", exist_ok=True)\n",
    "\n",
    "# Save as parquet for efficient storage\n",
    "skills_by_industry.write.mode(\"overwrite\").parquet(\"../analytics_output/query_results/skills_by_industry\")\n",
    "multi_skill_jobs.write.mode(\"overwrite\").parquet(\"../analytics_output/query_results/avg_skills_by_industry\")\n",
    "cross_industry_skills.write.mode(\"overwrite\").parquet(\"../analytics_output/query_results/cross_industry_skills\")\n",
    "\n",
    "# Also save as CSV for easy viewing\n",
    "skills_by_industry_pd.to_csv(\"../analytics_output/query_results/skills_by_industry.csv\", index=False)\n",
    "avg_skills_pd.to_csv(\"../analytics_output/query_results/avg_skills_by_industry.csv\", index=False)\n",
    "cross_industry_pd.to_csv(\"../analytics_output/query_results/cross_industry_skills.csv\", index=False)\n",
    "\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e92a6c",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8065a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visuals directory\n",
    "os.makedirs(\"../analytics_output/visuals\", exist_ok=True)\n",
    "\n",
    "# Plot 1: Top 10 Skills in Top 5 Industries\n",
    "top_5_industries = avg_skills_pd.nlargest(5, 'avg_skills_required')['industry_name'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Top 10 Skills by Industry', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, industry in enumerate(top_5_industries):\n",
    "    data = skills_by_industry_pd[skills_by_industry_pd['industry_name'] == industry].head(10)\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    sns.barplot(data=data, y='skill_name', x='skill_count', ax=ax, palette='viridis')\n",
    "    ax.set_title(f\"{industry}\", fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel(\"Job Postings\")\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "# Hide the 6th subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/top_skills_by_industry.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization 1 saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2558e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Average Skills Required by Industry\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20_avg = avg_skills_pd.head(20)\n",
    "sns.barplot(data=top_20_avg, y='industry_name', x='avg_skills_required', palette='magma')\n",
    "plt.title('Average Number of Skills Required by Industry (Top 20)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Average Skills Required', fontsize=12)\n",
    "plt.ylabel('Industry', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/avg_skills_by_industry.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization 2 saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8875c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Cross-Industry Skills (Most Versatile Skills)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_30_cross = cross_industry_pd.head(30)\n",
    "sns.barplot(data=top_30_cross, y='skill_name', x='num_industries', palette='coolwarm')\n",
    "plt.title('Most Versatile Skills (Appearing Across Industries)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Industries', fontsize=12)\n",
    "plt.ylabel('Skill Name', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/cross_industry_skills.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization 3 saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563a06f",
   "metadata": {},
   "source": [
    "## 🎓 Student-Focused Market Analysis\n",
    "### Enhanced Visualizations for Job Seekers\n",
    "\n",
    "The following visualizations provide actionable insights for students and new graduates entering the job market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086cb64",
   "metadata": {},
   "source": [
    "### Visualization 4: Skill Co-occurrence Network\n",
    "**Purpose:** Shows which skills are commonly required together in job postings.  \n",
    "**Student Value:** Learn skill bundles efficiently - if SQL and Python appear together often, learn both for maximum job opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Find top 20 most common skill pairs\n",
    "from pyspark.sql.functions import lit, concat_ws, array_sort, collect_list\n",
    "\n",
    "# Get skills per job\n",
    "skills_per_job = job_skills \\\n",
    "    .join(skill_map, \"skill_abr\") \\\n",
    "    .groupBy(\"job_id\") \\\n",
    "    .agg(collect_list(\"skill_name\").alias(\"skills\"))\n",
    "\n",
    "# Convert to pandas for analysis\n",
    "skills_per_job_pd = skills_per_job.toPandas()\n",
    "\n",
    "# Find skill pairs\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "skill_pairs = []\n",
    "for skills_list in skills_per_job_pd['skills']:\n",
    "    if len(skills_list) >= 2:\n",
    "        pairs = list(combinations(sorted(skills_list), 2))\n",
    "        skill_pairs.extend(pairs)\n",
    "\n",
    "# Count occurrences\n",
    "pair_counts = pd.DataFrame(skill_pairs, columns=['Skill_1', 'Skill_2'])\n",
    "pair_counts = pair_counts.groupby(['Skill_1', 'Skill_2']).size().reset_index(name='count')\n",
    "top_pairs = pair_counts.nlargest(20, 'count')\n",
    "\n",
    "print(\"=== Top 20 Skill Pairs ===\")\n",
    "print(top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize skill pairs as a heatmap-style chart\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Create a label for each pair\n",
    "top_pairs['pair_label'] = top_pairs['Skill_1'] + ' + ' + top_pairs['Skill_2']\n",
    "\n",
    "# Plot\n",
    "sns.barplot(data=top_pairs.head(15), y='pair_label', x='count', palette='rocket')\n",
    "plt.title('Top 15 Skill Combinations in Job Postings', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Number of Jobs Requiring Both Skills', fontsize=12)\n",
    "plt.ylabel('Skill Pair', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/skill_pairs.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Skill Pairs Visualization saved!\")\n",
    "print(\"\\nINSIGHT FOR STUDENTS:\")\n",
    "print(\"   Learn these skills together for maximum employability!\")\n",
    "print(f\"   Top combo: {top_pairs.iloc[0]['Skill_1']} + {top_pairs.iloc[0]['Skill_2']}\")\n",
    "print(f\"   ({top_pairs.iloc[0]['count']} jobs require both)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadff4f2",
   "metadata": {},
   "source": [
    "### Visualization 5: Top 10 Most In-Demand Skills Overall\n",
    "**Purpose:** Shows the absolute most demanded skills across all industries.  \n",
    "**Student Value:** Prioritize learning these skills first - they open the most doors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028200e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Top 10 most demanded skills overall\n",
    "top_skills_overall = job_skills \\\n",
    "    .join(skill_map, \"skill_abr\") \\\n",
    "    .groupBy(\"skill_name\") \\\n",
    "    .agg(count(\"job_id\").alias(\"job_count\")) \\\n",
    "    .orderBy(desc(\"job_count\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "print(\"=== Top 10 Most Demanded Skills ===\")\n",
    "top_skills_overall.show(truncate=False)\n",
    "\n",
    "# Convert to pandas\n",
    "top_skills_overall_pd = top_skills_overall.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an attractive visualization with percentages\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Calculate percentages\n",
    "total_skill_mentions = top_skills_overall_pd['job_count'].sum()\n",
    "top_skills_overall_pd['percentage'] = (top_skills_overall_pd['job_count'] / total_skill_mentions * 100).round(1)\n",
    "\n",
    "# Create horizontal bar chart with gradient\n",
    "colors = sns.color_palette(\"YlOrRd_r\", n_colors=10)\n",
    "bars = plt.barh(range(10), top_skills_overall_pd['job_count'], color=colors)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (count, pct) in enumerate(zip(top_skills_overall_pd['job_count'], top_skills_overall_pd['percentage'])):\n",
    "    plt.text(count + 100, i, f'{count:,} ({pct}%)', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.yticks(range(10), top_skills_overall_pd['skill_name'], fontsize=11)\n",
    "plt.xlabel('Number of Job Postings', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 10 Most In-Demand Skills (Learn These First!)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.gca().invert_yaxis()  # Highest at top\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/top_10_skills_overall.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top Skills Visualization saved!\")\n",
    "print(\"\\nCAREER TIP:\")\n",
    "print(f\"   The #1 most demanded skill is: {top_skills_overall_pd.iloc[0]['skill_name']}\")\n",
    "print(f\"   Found in {top_skills_overall_pd.iloc[0]['job_count']:,} job postings!\")\n",
    "print(f\"   Master the top 3 skills to qualify for {top_skills_overall_pd.head(3)['percentage'].sum():.1f}% of analyzed jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6581a",
   "metadata": {},
   "source": [
    "### Visualization 6: Industry Entry Barriers (Skills Required Distribution)\n",
    "**Purpose:** Shows how many skills different industries typically require.  \n",
    "**Student Value:** Choose industries matching your current skill level or understand the gap to close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16244b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bubble chart showing industry complexity\n",
    "# Use existing avg_skills_pd from earlier queries\n",
    "\n",
    "# Prepare data for visualization - take top 30 industries by job count\n",
    "industry_complexity = avg_skills_pd.copy()\n",
    "industry_complexity = industry_complexity.nlargest(30, 'total_jobs')\n",
    "\n",
    "# Create color categories based on skill requirements\n",
    "def categorize_complexity(avg_skills):\n",
    "    if avg_skills < 5:\n",
    "        return 'Entry-Friendly (< 5 skills)'\n",
    "    elif avg_skills < 7:\n",
    "        return 'Moderate (5-7 skills)'\n",
    "    else:\n",
    "        return 'Advanced (7+ skills)'\n",
    "\n",
    "industry_complexity['complexity'] = industry_complexity['avg_skills_required'].apply(categorize_complexity)\n",
    "\n",
    "# Create visualization\n",
    "colors_map = {\n",
    "    'Entry-Friendly (< 5 skills)': '#2ecc71',\n",
    "    'Moderate (5-7 skills)': '#f39c12', \n",
    "    'Advanced (7+ skills)': '#e74c3c'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Plot each category\n",
    "for category in ['Entry-Friendly (< 5 skills)', 'Moderate (5-7 skills)', 'Advanced (7+ skills)']:\n",
    "    data = industry_complexity[industry_complexity['complexity'] == category]\n",
    "    \n",
    "    if len(data) > 0:\n",
    "        ax.scatter(\n",
    "            data['avg_skills_required'], \n",
    "            data['total_jobs'],\n",
    "            s=data['total_jobs'] * 0.5,  # Bubble size proportional to jobs\n",
    "            alpha=0.6,\n",
    "            c=colors_map[category],\n",
    "            label=category,\n",
    "            edgecolors='black',\n",
    "            linewidth=1.5\n",
    "        )\n",
    "        \n",
    "        # Add industry labels for larger bubbles\n",
    "        for idx, row in data.nlargest(8, 'total_jobs').iterrows():\n",
    "            ax.annotate(\n",
    "                row['industry_name'][:25],  # Truncate long names\n",
    "                (row['avg_skills_required'], row['total_jobs']),\n",
    "                fontsize=9,\n",
    "                ha='left',\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7, edgecolor='gray')\n",
    "            )\n",
    "\n",
    "ax.set_xlabel('Average Skills Required', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Job Openings', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Industry Entry Barriers vs Opportunities', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(title='Complexity Level', fontsize=11, title_fontsize=12, loc='upper right')\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/industry_entry_barriers.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Industry Entry Barriers Visualization saved!\")\n",
    "print(\"\\nSTRATEGY FOR STUDENTS:\")\n",
    "entry_friendly = industry_complexity[industry_complexity['avg_skills_required'] < 5].head(5)\n",
    "if len(entry_friendly) > 0:\n",
    "    print(\"   Entry-Friendly Industries (start here):\")\n",
    "    for idx, row in entry_friendly.iterrows():\n",
    "        print(f\"      - {row['industry_name']}: ~{row['avg_skills_required']:.1f} skills, {row['total_jobs']} jobs\")\n",
    "else:\n",
    "    print(\"   Focus on building 5-7 core skills for moderate-entry industries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc03e",
   "metadata": {},
   "source": [
    "### Visualization 7: Skill Diversity Index\n",
    "**Purpose:** Shows which skills are specialized (narrow) vs generalist (broad).  \n",
    "**Student Value:** Understand if a skill is a safe investment (used everywhere) or niche specialty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f9590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine total demand with industry spread\n",
    "skill_diversity = top_skills_overall_pd.merge(\n",
    "    cross_industry_pd[['skill_name', 'num_industries']],\n",
    "    on='skill_name',\n",
    "    how='inner'  # Only skills in top 10\n",
    ").head(10)\n",
    "\n",
    "# Create quadrant chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Scatter plot with different colors for each skill\n",
    "scatter = plt.scatter(\n",
    "    skill_diversity['num_industries'],\n",
    "    skill_diversity['job_count'],\n",
    "    s=300,\n",
    "    c=range(len(skill_diversity)),\n",
    "    cmap='viridis',\n",
    "    alpha=0.7,\n",
    "    edgecolors='black',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Add labels for each skill\n",
    "for idx, row in skill_diversity.iterrows():\n",
    "    plt.annotate(\n",
    "        row['skill_name'],\n",
    "        (row['num_industries'], row['job_count']),\n",
    "        fontsize=11,\n",
    "        fontweight='bold',\n",
    "        ha='center',\n",
    "        xytext=(0, 15),\n",
    "        textcoords='offset points',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.6)\n",
    "    )\n",
    "\n",
    "# Add quadrant lines\n",
    "median_industries = skill_diversity['num_industries'].median()\n",
    "median_jobs = skill_diversity['job_count'].median()\n",
    "\n",
    "plt.axvline(median_industries, color='red', linestyle='--', alpha=0.5, linewidth=2, label='Median Industry Spread')\n",
    "plt.axhline(median_jobs, color='blue', linestyle='--', alpha=0.5, linewidth=2, label='Median Demand')\n",
    "\n",
    "# Add quadrant labels\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "plt.text(xlim[0] + (median_industries - xlim[0]) * 0.5, ylim[1] * 0.95, \n",
    "         'Specialized\\nHigh Demand', ha='center', fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "plt.text(median_industries + (xlim[1] - median_industries) * 0.5, ylim[1] * 0.95, \n",
    "         'Generalist\\nHigh Demand\\n(Best Investment)', ha='center', fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "plt.text(xlim[0] + (median_industries - xlim[0]) * 0.5, ylim[0] + (median_jobs - ylim[0]) * 0.5, \n",
    "         'Specialized\\nNiche', ha='center', fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.7))\n",
    "plt.text(median_industries + (xlim[1] - median_industries) * 0.5, ylim[0] + (median_jobs - ylim[0]) * 0.5, \n",
    "         'Generalist\\nModerate Demand', ha='center', fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "plt.xlabel('Number of Industries Using This Skill', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Total Job Postings Requiring This Skill', fontsize=12, fontweight='bold')\n",
    "plt.title('Skill Diversity vs Demand (Quadrant Analysis)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/skill_diversity_index.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Skill Diversity Index Visualization saved!\")\n",
    "print(\"\\nLEARNING PRIORITY:\")\n",
    "print(\"   BEST BET (Generalist + High Demand):\")\n",
    "best_bets = skill_diversity[(skill_diversity['num_industries'] > median_industries) & \n",
    "                             (skill_diversity['job_count'] > median_jobs)]\n",
    "if len(best_bets) > 0:\n",
    "    for idx, row in best_bets.iterrows():\n",
    "        print(f\"      - {row['skill_name']}: {row['num_industries']} industries, {row['job_count']:,} jobs\")\n",
    "else:\n",
    "    print(\"      All top skills show balanced diversity and demand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338e509",
   "metadata": {},
   "source": [
    "### Visualization 8: Career Path Builder\n",
    "**Purpose:** Shows learning progression - foundational skills vs advanced skills.  \n",
    "**Student Value:** Build a learning roadmap from beginner to advanced based on market data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a343f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze skill complexity based on how often they appear WITH other skills\n",
    "# More co-requirements = more advanced/specialized\n",
    "# Fewer co-requirements = more foundational/standalone\n",
    "\n",
    "# Calculate average number of OTHER skills required when this skill is listed\n",
    "skill_complexity_scores = []\n",
    "\n",
    "for skill in top_skills_overall_pd['skill_name'].head(15):\n",
    "    # Find jobs requiring this skill\n",
    "    skill_jobs = skills_per_job_pd[skills_per_job_pd['skills'].apply(lambda x: skill in x)]\n",
    "    \n",
    "    if len(skill_jobs) > 0:\n",
    "        # Calculate average number of skills in jobs requiring this skill\n",
    "        avg_skills_in_job = skill_jobs['skills'].apply(len).mean()\n",
    "        \n",
    "        skill_complexity_scores.append({\n",
    "            'skill': skill,\n",
    "            'avg_co_requirements': avg_skills_in_job,\n",
    "            'total_jobs': len(skill_jobs)\n",
    "        })\n",
    "\n",
    "complexity_df = pd.DataFrame(skill_complexity_scores).sort_values('avg_co_requirements')\n",
    "\n",
    "# Categorize based on co-requirements\n",
    "# Lower co-requirements = Foundation skills (can learn standalone)\n",
    "# Higher co-requirements = Advanced skills (need other skills first)\n",
    "complexity_df['level'] = pd.cut(\n",
    "    complexity_df['avg_co_requirements'], \n",
    "    bins=[0, 4.5, 6.5, 20], \n",
    "    labels=['Foundation', 'Intermediate', 'Advanced']\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Chart 1: Co-requirement scores\n",
    "colors_level = {'Foundation': '#2ecc71', 'Intermediate': '#f39c12', 'Advanced': '#e74c3c'}\n",
    "bars = ax1.barh(\n",
    "    complexity_df['skill'], \n",
    "    complexity_df['avg_co_requirements'],\n",
    "    color=[colors_level[level] for level in complexity_df['level']]\n",
    ")\n",
    "ax1.set_xlabel('Average Co-Requirements (Other Skills Needed)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Skill Learning Complexity', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add level labels\n",
    "for idx, (skill, score, level) in enumerate(zip(complexity_df['skill'], \n",
    "                                                  complexity_df['avg_co_requirements'], \n",
    "                                                  complexity_df['level'])):\n",
    "    ax1.text(score + 0.1, idx, f'{level}', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Chart 2: Learning path roadmap\n",
    "foundation = complexity_df[complexity_df['level'] == 'Foundation']\n",
    "intermediate = complexity_df[complexity_df['level'] == 'Intermediate']\n",
    "advanced = complexity_df[complexity_df['level'] == 'Advanced']\n",
    "\n",
    "y_pos = 0\n",
    "for level_name, data, color in [('Foundation\\n(Start Here)', foundation, '#2ecc71'),\n",
    "                                  ('Intermediate\\n(Build On)', intermediate, '#f39c12'),\n",
    "                                  ('Advanced\\n(Specialize)', advanced, '#e74c3c')]:\n",
    "    if len(data) > 0:\n",
    "        for skill in data['skill'].head(5):  # Max 5 per level\n",
    "            ax2.barh(y_pos, 1, color=color, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "            ax2.text(0.5, y_pos, skill, ha='center', va='center', \n",
    "                    fontsize=11, fontweight='bold', color='white',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.8))\n",
    "            y_pos += 1\n",
    "        y_pos += 0.5  # Gap between levels\n",
    "\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(-0.5, y_pos)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Suggested Learning Path', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../analytics_output/visuals/career_path_builder.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Career Path Builder Visualization saved!\")\n",
    "print(\"\\nYOUR LEARNING ROADMAP:\")\n",
    "if len(foundation) > 0:\n",
    "    print(\"\\n   FOUNDATION SKILLS (Learn First - Lower Prerequisites):\")\n",
    "    for skill in foundation['skill'].head(3):\n",
    "        print(f\"      - {skill}\")\n",
    "if len(intermediate) > 0:\n",
    "    print(\"\\n   INTERMEDIATE SKILLS (Build On Foundation):\")\n",
    "    for skill in intermediate['skill'].head(3):\n",
    "        print(f\"      - {skill}\")\n",
    "if len(advanced) > 0:\n",
    "    print(\"\\n   ADVANCED SKILLS (Specialize & Stand Out):\")\n",
    "    for skill in advanced['skill'].head(3):\n",
    "        print(f\"      - {skill}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6bb313",
   "metadata": {},
   "source": [
    "## 📋 Student Action Plan Summary\n",
    "### Key Takeaways & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a comprehensive student action plan\n",
    "print(\"=\"*70)\n",
    "print(\"PERSONALIZED JOB MARKET ACTION PLAN FOR STUDENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nVISUALIZATION SUMMARY:\")\n",
    "print(\"   - 8 Total Visualizations Created\")\n",
    "print(\"   - All saved to: ../analytics_output/visuals/\")\n",
    "print(\"\\n   1. Top Skills by Industry - Industry-specific skill requirements\")\n",
    "print(\"   2. Average Skills by Industry - Entry barriers analysis\")\n",
    "print(\"   3. Cross-Industry Skills - Transferable skills identification\")\n",
    "print(\"   4. Skill Pairs - Learn complementary skills together\")\n",
    "print(\"   5. Top 10 Overall Skills - Priority learning list\")\n",
    "print(\"   6. Entry Barriers - Industry accessibility vs opportunity\")\n",
    "print(\"   7. Skill Diversity Index - Specialist vs generalist skills\")\n",
    "print(\"   8. Career Path Builder - Foundation to Advanced progression\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"YOUR 90-DAY ACTION PLAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nMONTH 1: Build Foundation\")\n",
    "print(\"   Focus on the top 3 most demanded skills:\")\n",
    "if len(top_skills_overall_pd) >= 3:\n",
    "    for i in range(3):\n",
    "        skill = top_skills_overall_pd.iloc[i]\n",
    "        print(f\"      {i+1}. {skill['skill_name']}\")\n",
    "        print(f\"         Found in {skill['job_count']:,} jobs ({skill['percentage']:.1f}% of market)\")\n",
    "\n",
    "print(\"\\nMONTH 2: Add Complementary Skills\")\n",
    "print(\"   Learn these skill combinations together:\")\n",
    "if len(top_pairs) >= 3:\n",
    "    for i in range(min(3, len(top_pairs))):\n",
    "        pair = top_pairs.iloc[i]\n",
    "        print(f\"      - {pair['Skill_1']} + {pair['Skill_2']}\")\n",
    "        print(f\"        {pair['count']} jobs require both\")\n",
    "\n",
    "print(\"\\nMONTH 3: Choose Your Path\")\n",
    "print(\"   Select an industry based on:\")\n",
    "if len(industry_complexity) > 0:\n",
    "    entry_industries = industry_complexity[industry_complexity['avg_skills_required'] < 5].head(3)\n",
    "    if len(entry_industries) > 0:\n",
    "        print(\"   Entry-Friendly Options:\")\n",
    "        for idx, row in entry_industries.iterrows():\n",
    "            print(f\"      - {row['industry_name']}\")\n",
    "            print(f\"        Skills needed: ~{row['avg_skills_required']:.1f}\")\n",
    "            print(f\"        Job openings: {row['total_jobs']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMMEDIATE NEXT STEPS\")\n",
    "print(\"=\"*70)\n",
    "print(\"   1. Review all 8 visualizations in ../analytics_output/visuals/\")\n",
    "print(\"   2. Pick your target industry from Visualization 6\")\n",
    "print(\"   3. Learn the top 3 skills from Visualization 5\")\n",
    "print(\"   4. Build skill pairs from Visualization 4\")\n",
    "print(\"   5. Follow the learning path in Visualization 8\")\n",
    "print(\"   6. Apply to jobs in entry-friendly industries first\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUCCESS METRICS TO TRACK\")\n",
    "print(\"=\"*70)\n",
    "print(\"   [ ] Master 3 foundation skills in 30 days\")\n",
    "print(\"   [ ] Complete 1 skill pair (complementary skills) in 60 days\")\n",
    "print(\"   [ ] Apply to 5 entry-friendly industry jobs in 90 days\")\n",
    "print(\"   [ ] Build portfolio project using top 5 skills\")\n",
    "print(\"   [ ] Network with professionals in chosen industry\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REMEMBER: You don't need ALL skills, just the RIGHT skills!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save action plan to file\n",
    "with open(\"../analytics_output/STUDENT_ACTION_PLAN.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"PERSONALIZED JOB MARKET ACTION PLAN FOR STUDENTS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(\"Generated from LinkedIn Job Market Analysis\\n\")\n",
    "    f.write(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 10 MOST DEMANDED SKILLS:\\n\")\n",
    "    for idx, row in top_skills_overall_pd.iterrows():\n",
    "        f.write(f\"   {idx+1}. {row['skill_name']}: {row['job_count']:,} jobs\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nTOP SKILL COMBINATIONS:\\n\")\n",
    "    for idx, row in top_pairs.head(10).iterrows():\n",
    "        f.write(f\"   - {row['Skill_1']} + {row['Skill_2']}: {row['count']} jobs\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nENTRY-FRIENDLY INDUSTRIES:\\n\")\n",
    "    entry_industries = industry_complexity[industry_complexity['avg_skills_required'] < 5].head(5)\n",
    "    for idx, row in entry_industries.iterrows():\n",
    "        f.write(f\"   - {row['industry_name']}: ~{row['avg_skills_required']:.1f} skills, {row['total_jobs']} openings\\n\")\n",
    "\n",
    "print(\"\\nStudent action plan saved to: ../analytics_output/STUDENT_ACTION_PLAN.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2f0cb",
   "metadata": {},
   "source": [
    "## Summary Statistics for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMPLEX QUERIES SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal Industries Analyzed: {industry_map_clean.count()}\")\n",
    "print(f\"Total Unique Skills: {skill_map.count()}\")\n",
    "print(f\"Total Job Postings: {postings.count()}\")\n",
    "print(f\"\\nQuery 1: Identified top 10 skills for each industry\")\n",
    "print(f\"Query 2: Calculated average skills required across {avg_skills_pd.shape[0]} industries\")\n",
    "print(f\"Query 3: Found {cross_industry_pd.shape[0]} skills used across industries\")\n",
    "print(f\"\\nAll results saved to: ../analytics_output/query_results/\")\n",
    "print(f\"All visualizations saved to: ../analytics_output/visuals/\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
